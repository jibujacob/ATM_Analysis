{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATM Transactions Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up environment variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below parameters needs to be updated with respective environments values\n",
    "\n",
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/opt/cloudera/parcels/Anaconda/bin/python\"\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/java/jdk1.8.0_232-cloudera/jre\" \n",
    "os.environ[\"SPARK_HOME\"]=\"/opt/cloudera/parcels/SPARK2-2.3.0.cloudera2-1.cdh5.13.3.p0.316101/lib/spark2/\" \n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.6-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Spark Session and Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-10-0-0-137.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0.cloudera2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ATM_Transactions_Project</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fdb2429d110>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('ATM_Transactions_Project').master(\"local\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling the data from HDFS , setting up the schema as per the required output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, BooleanType, DoubleType, LongType\n",
    "\n",
    "atmSchema = StructType([StructField('year', IntegerType(),False),\n",
    "                        StructField('month', StringType(),False),\n",
    "                        StructField('day', IntegerType(),False),\n",
    "                        StructField('weekday', StringType(),False),\n",
    "                        StructField('hour', IntegerType(),False),\n",
    "                        StructField('atm_status', StringType(),False),\n",
    "                        StructField('atm_id', IntegerType(),False),\n",
    "                        StructField('atm_manufacturer', StringType(),False),\n",
    "                        StructField('atm_location', StringType(),False),\n",
    "                        StructField('atm_streetname', StringType(),False),\n",
    "                        StructField('atm_street_number', IntegerType(),False),\n",
    "                        StructField('atm_zipcode', IntegerType(),False),\n",
    "                        StructField('atm_lat', DoubleType(),False),\n",
    "                        StructField('atm_lon', DoubleType(),False),\n",
    "                        StructField('currency', StringType(),False),\n",
    "                        StructField('card_type', StringType(),False),\n",
    "                        StructField('transaction_amount', IntegerType(),False), \n",
    "                        StructField('service', StringType(),False),\n",
    "                        StructField('message_code', StringType(),True),\n",
    "                        StructField('message_text', StringType(),True),\n",
    "                        StructField('weather_lat', DoubleType(),False),\n",
    "                        StructField('weather_lon', DoubleType(),False),\n",
    "                        StructField('weather_city_id', IntegerType(),False),\n",
    "                        StructField('weather_city_name', StringType(),False), \n",
    "                        StructField('temp', DoubleType(),False),\n",
    "                        StructField('pressure', IntegerType(),False), \n",
    "                        StructField('humidity', IntegerType(),False), \n",
    "                        StructField('wind_speed', IntegerType(),False), \n",
    "                        StructField('wind_deg', IntegerType(),False), \n",
    "                        StructField('rain_3h', DoubleType(),True), \n",
    "                        StructField('clouds_all', IntegerType(),False), \n",
    "                        StructField('weather_id', IntegerType(),False), \n",
    "                        StructField('weather_main', StringType(),False), \n",
    "                        StructField('weather_description', StringType(),False), \n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "atm_staging = spark.read.csv(\"/user/root/etl_assignment\",header=False,schema=atmSchema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- atm_id: integer (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: double (nullable = true)\n",
      " |-- atm_lon: double (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: double (nullable = true)\n",
      " |-- weather_lon: double (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "atm_staging.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the count of the entries pulled from RDS to Spark(HDFS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atm_staging.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+----------------+-------+------------+----------+\n",
      "|year|atm_id|atm_manufacturer|atm_lat|message_code|clouds_all|\n",
      "+----+------+----------------+-------+------------+----------+\n",
      "|2017|     1|             NCR| 55.233|        null|        92|\n",
      "|2017|     2|             NCR| 57.043|        null|        92|\n",
      "|2017|     2|             NCR| 57.043|        null|        92|\n",
      "+----+------+----------------+-------+------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "atm_staging.select(\"year\",\"atm_id\",\"atm_manufacturer\",\"atm_lat\",\"message_code\",\"clouds_all\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating staging table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[year: int, month: string, day: int, weekday: string, hour: int, atm_status: string, atm_id: int, atm_manufacturer: string, atm_location: string, atm_streetname: string, atm_street_number: int, atm_zipcode: int, atm_lat: double, atm_lon: double, currency: string, card_type: string, transaction_amount: int, service: string, message_code: string, message_text: string, weather_lat: double, weather_lon: double, weather_city_id: int, weather_city_name: string, temp: double, pressure: int, humidity: int, wind_speed: int, wind_deg: int, rain_3h: double, clouds_all: int, weather_id: int, weather_main: string, weather_description: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atm_staging.registerTempTable(\"atm_staging\");\n",
    "atm_staging.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 2468572|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(1) from atm_staging\").show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Table Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Dimension Table Creation - DIM_LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pacakges to create unique id \n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import row_number, monotonically_increasing_id\n",
    "from pyspark.sql import Window\n",
    "\n",
    "# Creating staging table for Location dimension table and removing the duplicates\n",
    "atm_location_staging=spark.sql(\"select distinct atm_location location, \\\n",
    "          atm_streetname streetname, \\\n",
    "          atm_street_number street_number,\\\n",
    "          atm_zipcode zipcode, \\\n",
    "          atm_lat lat, \\\n",
    "          atm_lon lon \\\n",
    "          from atm_staging \\\n",
    "          order by location\");\n",
    "\n",
    "# Adding the primary key column by generating unique id \n",
    "atm_location_staging = atm_location_staging.withColumn(\n",
    "    \"location_id\",\n",
    "    row_number().over(Window.orderBy(monotonically_increasing_id()))\n",
    ")\n",
    "\n",
    "# Creating the dimension table by rearragning the columns as per expectation\n",
    "DIM_LOCATION=atm_location_staging.select(\"location_id\",\"location\",\"streetname\",\"street_number\",\"zipcode\",\"lat\",\"lon\")\n",
    "\n",
    "#Registering the df to use in join with sparlsql\n",
    "DIM_LOCATION.registerTempTable(\"DIM_LOCATION\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIM_LOCATION Validate the count -109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     109|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from DIM_LOCATION\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIM_LOCATION.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the DIM_LOCATION Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------------+------------------------+-------------+-------+------+------+\n",
      "|location_id|location                   |streetname              |street_number|zipcode|lat   |lon   |\n",
      "+-----------+---------------------------+------------------------+-------------+-------+------+------+\n",
      "|1          |Aabybro                    |ÃƒËœstergade            |6            |9440   |57.162|9.73  |\n",
      "|2          |Aalborg Hallen             |Europa Plads            |4            |9000   |57.044|9.913 |\n",
      "|3          |Aalborg Storcenter  Afd    |Hobrovej                |452          |9200   |57.005|9.876 |\n",
      "|4          |Aalborg Storcenter indg. D |Hobrovej                |452          |9200   |57.005|9.876 |\n",
      "|5          |Aalborg Syd                |Hobrovej                |440          |9200   |57.005|9.881 |\n",
      "|6          |AalbÃƒÂ¦k                  |Centralvej              |5            |9982   |57.593|10.412|\n",
      "|7          |Aarhus                     |SÃƒÂ¸nder Alle          |11           |8000   |56.153|10.206|\n",
      "|8          |Aarhus                     |Ceres Byen              |75           |8000   |56.157|10.194|\n",
      "|9          |Aarhus Lufthavn            |Ny Lufthavnsvej         |24           |8560   |56.308|10.627|\n",
      "|10         |Aars                       |Himmerlandsgade         |70           |9600   |56.803|9.518 |\n",
      "|11         |Abildgaard                 |HjÃƒÂ¸rringvej          |144          |9900   |57.447|10.506|\n",
      "|12         |Arden                      |Vestergade              |6            |9510   |56.769|9.859 |\n",
      "|13         |Bindslev                   |NÃƒÂ¸rrebro             |18           |9881   |57.541|10.2  |\n",
      "|14         |Bispensgade                |Bispensgade             |35           |9800   |57.453|9.996 |\n",
      "|15         |Brugsen ANS                |SÃƒÂ¸ndermarksgade      |14           |8643   |56.306|9.594 |\n",
      "|16         |Brugsen i Breum            |AakjÃƒÂ¦rsvej           |1            |7870   |56.688|9.069 |\n",
      "|17         |Bryggen  Vejle             |SÃƒÂ¸nderbrogade        |2            |7100   |55.705|9.532 |\n",
      "|18         |BrÃƒÂ¸nderslev             |Algade                  |4            |9700   |57.269|9.945 |\n",
      "|19         |DAYZ Feriecenter           |LivÃƒÂ¸vej              |80           |9681   |56.893|9.171 |\n",
      "|20         |Daglig Brugsen ÃƒËœ.Hurup  |Kystvejen               |51           |9560   |56.804|10.271|\n",
      "|21         |Drive Up  Vejle            |Havneparken             |4            |7100   |55.707|9.541 |\n",
      "|22         |Durup                      |Torvet                  |4            |7870   |56.745|8.949 |\n",
      "|23         |Esbjerg                    |Strandbygade            |20           |6700   |55.468|8.44  |\n",
      "|24         |FarsÃƒÂ¸                   |Torvet                  |8            |9640   |56.771|9.34  |\n",
      "|25         |Fredericia                 |SjÃƒÂ¦llandsgade        |33           |7000   |55.564|9.757 |\n",
      "|26         |Frederiksberg              |Gammel Kongevej         |157          |1850   |55.677|12.537|\n",
      "|27         |Frederikshavn              |Danmarksgade            |48           |9900   |57.441|10.537|\n",
      "|28         |Fur                        |StenÃƒÂ¸re              |19           |7884   |56.805|9.02  |\n",
      "|29         |Gistrup                    |Hadsundvej              |346          |9260   |56.997|9.993 |\n",
      "|30         |GlyngÃƒÂ¸re                |FÃƒÂ¦rgevej             |1            |7870   |56.762|8.867 |\n",
      "|31         |Hadsund                    |Storegade               |12           |9560   |56.716|10.114|\n",
      "|32         |Hasseris                   |Hasserisvej             |113          |9000   |57.044|9.898 |\n",
      "|33         |HelsingÃƒÂ¸r               |Sct. Olai Gade          |39           |3000   |56.036|12.612|\n",
      "|34         |Herning                    |Dalgasgade              |30           |7400   |56.135|8.971 |\n",
      "|35         |HillerÃƒÂ¸d                |KÃƒÂ¸benhavnsvej        |31           |3400   |55.933|12.314|\n",
      "|36         |HillerÃƒÂ¸d IdrÃƒÂ¦tscenter|Milnersvej              |39           |3400   |55.921|12.299|\n",
      "|37         |Hirtshals                  |JÃƒÂ¸rgen Fibigersgade  |4            |9850   |57.591|9.957 |\n",
      "|38         |Hjallerup                  |Hjallerup Centret       |18           |9320   |57.168|10.148|\n",
      "|39         |HjÃƒÂ¸rring                |ÃƒËœstergade            |8            |9800   |57.459|9.988 |\n",
      "|40         |Hobro                      |Adelgade                |31           |9500   |56.638|9.794 |\n",
      "|41         |HolbÃƒÂ¦k                  |Slotsvolden             |7            |4300   |55.718|11.704|\n",
      "|42         |Holstebro                  |Hostrupsvej             |6            |7500   |56.373|8.625 |\n",
      "|43         |Horsens                    |GrÃƒÂ¸nlandsvej         |5            |8700   |55.859|9.854 |\n",
      "|44         |HÃƒÂ¸jbjerg                |Rosenvangsalle          |194          |8270   |56.119|10.192|\n",
      "|45         |HÃƒÂ¸jslev                 |ÃƒËœsterrisvej          |2            |7840   |56.551|9.11  |\n",
      "|46         |HÃƒÂ¸rning                 |NÃƒÂ¸rrealle            |12           |8362   |56.086|10.037|\n",
      "|47         |HÃƒÂ¸rning Hallen          |Toftevej                |53           |8362   |56.091|10.033|\n",
      "|48         |Ikast                      |RÃƒÂ¥dhusstrÃƒÂ¦det     |12           |7430   |56.139|9.154 |\n",
      "|49         |Intern  BrÃƒÂ¸nderslev     |Algade                  |4            |9700   |57.269|9.945 |\n",
      "|50         |Intern  Frederikshavn      |Danmarksgade            |48           |9900   |57.441|10.537|\n",
      "|51         |Intern  Hjallerup          |Hjallerup Centret       |18           |9320   |57.168|10.148|\n",
      "|52         |Intern  HjÃƒÂ¸rring        |ÃƒËœstergade            |8            |9800   |57.459|9.988 |\n",
      "|53         |Intern  KÃƒÂ¸benhavn       |RÃƒÂ¥dhuspladsen        |75           |1550   |55.676|12.571|\n",
      "|54         |Intern  Odense             |FÃƒÂ¦lledvej            |3            |5000   |55.394|10.37 |\n",
      "|55         |Intern  Roskilde           |KÃƒÂ¸benhavnsvej        |65           |4000   |55.642|12.106|\n",
      "|56         |Intern  Skive              |Adelgade                |8            |7800   |56.567|9.027 |\n",
      "|57         |Intern  Vejle              |Havneparken             |4            |7100   |55.707|9.541 |\n",
      "|58         |Intern  ÃƒËœsterÃƒÂ¥       |ÃƒËœsterÃƒÂ¥            |12           |9000   |57.049|9.922 |\n",
      "|59         |Intern HolbÃƒÂ¦k           |Slotsvolden             |7            |4300   |55.718|11.704|\n",
      "|60         |Intern Skagen              |Sct. Laurentiivej       |36           |9990   |57.723|10.59 |\n",
      "|61         |Jebjerg                    |Kirkegade               |4            |7870   |56.671|9.013 |\n",
      "|62         |Kolding                    |Vejlevej                |135          |6000   |55.505|9.457 |\n",
      "|63         |KÃƒÂ¸benhavn               |Regnbuepladsen          |5            |1550   |55.676|12.571|\n",
      "|64         |KÃƒÂ¸ge                    |SÃƒÂ¸ndre Alle          |1            |4600   |55.454|12.181|\n",
      "|65         |Lyngby                     |Jernbanevej             |6            |2800   |55.772|12.5  |\n",
      "|66         |LÃƒÂ¸gstÃƒÂ¸r              |ÃƒËœsterbrogade         |8            |9670   |56.967|9.253 |\n",
      "|67         |Menu KÃƒÂ¸bmand Klarup     |Klarupvej               |52           |9270   |57.013|10.046|\n",
      "|68         |Middelfart                 |Brogade                 |9            |5500   |55.507|9.727 |\n",
      "|69         |Nibe                       |Torvet                  |1            |9240   |56.983|9.639 |\n",
      "|70         |Nordkraft                  |Kjellerups Torv         |1            |9000   |57.047|9.932 |\n",
      "|71         |Nyborg                     |Vestergade              |35           |5800   |55.318|10.781|\n",
      "|72         |NykÃƒÂ¸bing Mors           |Kirketorvet             |1            |7900   |56.795|8.86  |\n",
      "|73         |NykÃƒÂ¸bing Mors Lobby     |Kirketorvet             |1            |7900   |56.795|8.86  |\n",
      "|74         |NÃƒÂ¦stved                 |Farimagsgade            |8            |4700   |55.69 |12.575|\n",
      "|75         |NÃƒÂ¦stved                 |Farimagsvej             |8            |4700   |55.233|11.763|\n",
      "|76         |NÃƒÂ¸rresundby             |Torvet                  |6            |9400   |57.059|9.922 |\n",
      "|77         |Odense                     |FÃƒÂ¦lledvej            |3            |5000   |55.394|10.37 |\n",
      "|78         |Randers                    |ÃƒËœstervold            |16           |8900   |56.462|10.038|\n",
      "|79         |Roskilde                   |KÃƒÂ¸benhavnsvej        |65           |4000   |55.642|12.106|\n",
      "|80         |Sauersvej                  |Fridtjof Nansens Vej    |2            |9210   |57.023|9.94  |\n",
      "|81         |Silkeborg                  |Borgergade              |36           |8600   |56.179|9.552 |\n",
      "|82         |Skagen                     |Sct. Laurentiivej       |36           |9990   |57.723|10.59 |\n",
      "|83         |Skallerup Klit             |Nordre Klitvej          |21           |9800   |57.494|9.838 |\n",
      "|84         |Skelagervej 15             |Skelagervej             |15           |9000   |57.023|9.891 |\n",
      "|85         |Skipperen                  |Vestre Alle             |2            |9000   |57.034|9.908 |\n",
      "|86         |Skive                      |Adelgade                |8            |7800   |56.567|9.027 |\n",
      "|87         |Skive Lobby                |Adelgade                |8            |7800   |56.567|9.027 |\n",
      "|88         |Slagelse                   |Mariendals AllÃƒÂ¨      |29           |4200   |55.398|11.342|\n",
      "|89         |Slagelse                   |Mariendals Alle         |29           |4200   |55.398|11.342|\n",
      "|90         |Spar KÃƒÂ¸bmand TornhÃƒÂ¸j |TornhÃƒÂ¸jvej           |4            |9220   |57.026|10.002|\n",
      "|91         |Storcenter indg. A         |Hobrovej                |452          |9200   |57.005|9.876 |\n",
      "|92         |Storvorde                  |VandvÃƒÂ¦rksvej         |2            |9280   |57.005|10.101|\n",
      "|93         |StÃƒÂ¸vring                |Baunebakken             |4            |9530   |56.89 |9.836 |\n",
      "|94         |Svendborg                  |Sankt Nicolai Gade      |1            |5700   |55.058|10.609|\n",
      "|95         |Svenstrup                  |GodthÃƒÂ¥bsvej          |14           |9230   |56.973|9.851 |\n",
      "|96         |Svogerslev                 |BrÃƒÂ¸nsager            |1            |4000   |55.634|12.018|\n",
      "|97         |SÃƒÂ¦by                    |Vestergade              |3            |9300   |57.334|10.515|\n",
      "|98         |SÃƒÂ¦by Syd                |Trafikcenter SÃƒÂ¦by Syd|1            |9300   |57.313|10.45 |\n",
      "|99         |SÃƒÂ¦dding                 |Tarphagevej             |59           |6710   |55.498|8.408 |\n",
      "|100        |Taars                      |Bredgade                |91           |9830   |57.385|10.116|\n",
      "|101        |Terndrup                   |Bymidten                |2            |9575   |56.815|10.057|\n",
      "|102        |Vadum                      |Ellehammersvej          |43           |9430   |57.118|9.861 |\n",
      "|103        |Vejgaard                   |Hadsundvej              |20           |9000   |57.043|9.95  |\n",
      "|104        |Vestre                     |Kastetvej               |36           |9000   |57.053|9.905 |\n",
      "|105        |Viborg                     |Toldboden               |3            |8800   |56.448|9.401 |\n",
      "|106        |Vinderup                   |SÃƒÂ¸ndergade           |5            |7830   |56.481|8.779 |\n",
      "|107        |Vodskov                    |Vodskovvej              |27           |9310   |57.104|10.027|\n",
      "|108        |ÃƒËœsterÃƒÂ¥  Duus         |ÃƒËœsterÃƒÂ¥            |12           |9000   |57.049|9.922 |\n",
      "|109        |ÃƒËœsterÃƒÂ¥  MÃƒÂ¸ller    |ÃƒËœsterÃƒÂ¥            |12           |9000   |57.049|9.922 |\n",
      "+-----------+---------------------------+------------------------+-------------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from DIM_LOCATION\").show(109,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATM Dimension Table Creation - DIM_ATM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pacakges to create unique id \n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import row_number, monotonically_increasing_id\n",
    "from pyspark.sql import Window\n",
    "\n",
    "# Creating staging table for ATM dimension table and removing the duplicates\n",
    "atm_data_staging=spark.sql(\"select distinct atm_id atm_number, \\\n",
    "          atm_manufacturer, \\\n",
    "          atm_lat, \\\n",
    "          atm_lon \\\n",
    "          from atm_staging\");\n",
    "\n",
    "#Generating the temp table to perfor join later with the DIM_LOCATION table\n",
    "atm_data_staging.registerTempTable(\"atm_data_staging\");\n",
    "\n",
    "#Joining the tables to get normalized data based on location of atm\n",
    "atm_data_staging=spark.sql(\"select distinct atm_number , \\\n",
    "          atm_manufacturer, \\\n",
    "          location_id atm_location_id\\\n",
    "          from atm_data_staging \\\n",
    "          left outer join DIM_LOCATION \\\n",
    "          on atm_data_staging.atm_lat = lat \\\n",
    "          and atm_data_staging.atm_lon = lon\")\n",
    "\n",
    "# Adding the primary key column by generating unique id \n",
    "atm_data_staging = atm_data_staging.withColumn(\n",
    "    \"atm_id\",\n",
    "    row_number().over(Window.orderBy(monotonically_increasing_id()))\n",
    ")\n",
    "\n",
    "# Creating the dimension table by rearragning the columns as per expectation\n",
    "DIM_ATM=atm_data_staging.select(\"atm_id\",\"atm_number\",\"atm_manufacturer\",\"atm_location_id\");\n",
    "\n",
    "#Registering the df to use in join with sparlsql\n",
    "DIM_ATM.registerTempTable(\"DIM_ATM\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIM_ATM Validate the count -156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     156|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(1) from DIM_ATM\").show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the DIM_ATM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------------+---------------+\n",
      "|atm_id|atm_number|atm_manufacturer|atm_location_id|\n",
      "+------+----------+----------------+---------------+\n",
      "|1     |29        |NCR             |84             |\n",
      "|2     |110       |Diebold Nixdorf |59             |\n",
      "|3     |105       |Diebold Nixdorf |76             |\n",
      "|4     |111       |Diebold Nixdorf |8              |\n",
      "|5     |87        |NCR             |3              |\n",
      "|6     |100       |NCR             |87             |\n",
      "|7     |2         |NCR             |103            |\n",
      "|8     |21        |NCR             |108            |\n",
      "|9     |91        |NCR             |86             |\n",
      "|10    |18        |Diebold Nixdorf |105            |\n",
      "|11    |6         |NCR             |25             |\n",
      "|12    |36        |NCR             |52             |\n",
      "|13    |82        |NCR             |83             |\n",
      "|14    |41        |Diebold Nixdorf |82             |\n",
      "|15    |59        |Diebold Nixdorf |72             |\n",
      "|16    |88        |NCR             |4              |\n",
      "|17    |15        |NCR             |104            |\n",
      "|18    |42        |NCR             |106            |\n",
      "|19    |106       |NCR             |79             |\n",
      "|20    |43        |NCR             |10             |\n",
      "|21    |34        |NCR             |85             |\n",
      "|22    |20        |NCR             |14             |\n",
      "|23    |100       |NCR             |86             |\n",
      "|24    |104       |NCR             |109            |\n",
      "|25    |31        |NCR             |89             |\n",
      "|26    |87        |NCR             |4              |\n",
      "|27    |88        |NCR             |3              |\n",
      "|28    |67        |NCR             |45             |\n",
      "|29    |19        |NCR             |62             |\n",
      "|30    |63        |NCR             |16             |\n",
      "|31    |25        |Diebold Nixdorf |77             |\n",
      "|32    |96        |NCR             |2              |\n",
      "|33    |102       |NCR             |3              |\n",
      "|34    |14        |NCR             |46             |\n",
      "|35    |77        |NCR             |9              |\n",
      "|36    |113       |Diebold Nixdorf |89             |\n",
      "|37    |66        |NCR             |15             |\n",
      "|38    |85        |Diebold Nixdorf |63             |\n",
      "|39    |93        |NCR             |49             |\n",
      "|40    |61        |NCR             |23             |\n",
      "|41    |58        |NCR             |93             |\n",
      "|42    |44        |NCR             |65             |\n",
      "|43    |94        |NCR             |82             |\n",
      "|44    |16        |NCR             |87             |\n",
      "|45    |100       |NCR             |56             |\n",
      "|46    |93        |NCR             |18             |\n",
      "|47    |16        |NCR             |86             |\n",
      "|48    |94        |NCR             |60             |\n",
      "|49    |113       |Diebold Nixdorf |88             |\n",
      "|50    |76        |NCR             |19             |\n",
      "|51    |109       |Diebold Nixdorf |5              |\n",
      "|52    |72        |NCR             |20             |\n",
      "|53    |46        |Diebold Nixdorf |33             |\n",
      "|54    |89        |NCR             |27             |\n",
      "|55    |27        |NCR             |34             |\n",
      "|56    |104       |NCR             |108            |\n",
      "|57    |32        |NCR             |99             |\n",
      "|58    |47        |NCR             |26             |\n",
      "|59    |79        |NCR             |68             |\n",
      "|60    |12        |NCR             |109            |\n",
      "|61    |51        |NCR             |29             |\n",
      "|62    |104       |NCR             |58             |\n",
      "|63    |12        |NCR             |108            |\n",
      "|64    |59        |Diebold Nixdorf |73             |\n",
      "|65    |36        |NCR             |39             |\n",
      "|66    |81        |NCR             |90             |\n",
      "|67    |53        |NCR             |98             |\n",
      "|68    |69        |NCR             |100            |\n",
      "|69    |84        |NCR             |94             |\n",
      "|70    |68        |NCR             |57             |\n",
      "|71    |38        |NCR             |32             |\n",
      "|72    |41        |Diebold Nixdorf |60             |\n",
      "|73    |68        |NCR             |21             |\n",
      "|74    |39        |NCR             |95             |\n",
      "|75    |7         |Diebold Nixdorf |51             |\n",
      "|76    |95        |NCR             |63             |\n",
      "|77    |54        |NCR             |22             |\n",
      "|78    |40        |Diebold Nixdorf |27             |\n",
      "|79    |101       |NCR             |17             |\n",
      "|80    |85        |Diebold Nixdorf |53             |\n",
      "|81    |3         |NCR             |48             |\n",
      "|82    |26        |NCR             |59             |\n",
      "|83    |56        |Diebold Nixdorf |64             |\n",
      "|84    |55        |NCR             |12             |\n",
      "|85    |74        |NCR             |61             |\n",
      "|86    |87        |NCR             |91             |\n",
      "|87    |45        |NCR             |11             |\n",
      "|88    |91        |NCR             |87             |\n",
      "|89    |97        |NCR             |38             |\n",
      "|90    |50        |NCR             |7              |\n",
      "|91    |75        |NCR             |70             |\n",
      "|92    |9         |Diebold Nixdorf |31             |\n",
      "|93    |112       |Diebold Nixdorf |74             |\n",
      "|94    |83        |NCR             |28             |\n",
      "|95    |86        |NCR             |36             |\n",
      "|96    |52        |NCR             |24             |\n",
      "|97    |12        |NCR             |58             |\n",
      "|98    |90        |NCR             |41             |\n",
      "|99    |28        |NCR             |66             |\n",
      "|100   |4         |NCR             |96             |\n",
      "|101   |103       |Diebold Nixdorf |103            |\n",
      "|102   |65        |NCR             |92             |\n",
      "|103   |23        |Diebold Nixdorf |107            |\n",
      "|104   |26        |NCR             |41             |\n",
      "|105   |22        |NCR             |79             |\n",
      "|106   |24        |NCR             |40             |\n",
      "|107   |64        |NCR             |43             |\n",
      "|108   |31        |NCR             |88             |\n",
      "|109   |110       |Diebold Nixdorf |41             |\n",
      "|110   |71        |NCR             |6              |\n",
      "|111   |8         |NCR             |30             |\n",
      "|112   |33        |NCR             |102            |\n",
      "|113   |1         |NCR             |75             |\n",
      "|114   |95        |NCR             |53             |\n",
      "|115   |108       |NCR             |47             |\n",
      "|116   |10        |NCR             |76             |\n",
      "|117   |40        |Diebold Nixdorf |50             |\n",
      "|118   |97        |NCR             |51             |\n",
      "|119   |21        |NCR             |58             |\n",
      "|120   |80        |NCR             |67             |\n",
      "|121   |5         |NCR             |69             |\n",
      "|122   |98        |NCR             |54             |\n",
      "|123   |70        |Diebold Nixdorf |42             |\n",
      "|124   |90        |NCR             |59             |\n",
      "|125   |107       |Diebold Nixdorf |62             |\n",
      "|126   |106       |NCR             |55             |\n",
      "|127   |92        |NCR             |39             |\n",
      "|128   |25        |Diebold Nixdorf |54             |\n",
      "|129   |78        |Diebold Nixdorf |71             |\n",
      "|130   |21        |NCR             |109            |\n",
      "|131   |57        |NCR             |35             |\n",
      "|132   |92        |NCR             |52             |\n",
      "|133   |102       |NCR             |4              |\n",
      "|134   |88        |NCR             |91             |\n",
      "|135   |91        |NCR             |56             |\n",
      "|136   |7         |Diebold Nixdorf |38             |\n",
      "|137   |98        |NCR             |77             |\n",
      "|138   |73        |NCR             |44             |\n",
      "|139   |37        |NCR             |81             |\n",
      "|140   |11        |NCR             |80             |\n",
      "|141   |102       |NCR             |91             |\n",
      "|142   |30        |NCR             |72             |\n",
      "|143   |48        |Diebold Nixdorf |49             |\n",
      "|144   |30        |NCR             |73             |\n",
      "|145   |22        |NCR             |55             |\n",
      "|146   |35        |NCR             |1              |\n",
      "|147   |89        |NCR             |50             |\n",
      "|148   |17        |NCR             |78             |\n",
      "|149   |62        |Diebold Nixdorf |101            |\n",
      "|150   |49        |NCR             |13             |\n",
      "|151   |99        |NCR             |21             |\n",
      "|152   |60        |NCR             |37             |\n",
      "|153   |48        |Diebold Nixdorf |18             |\n",
      "|154   |99        |NCR             |57             |\n",
      "|155   |13        |NCR             |97             |\n",
      "|156   |16        |NCR             |56             |\n",
      "+------+----------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from DIM_ATM\").show(156,truncate=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATM Transaction date Dimension Table Creation - DIM_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pacakges to create unique id \n",
    "from pyspark.sql import functions as sf\n",
    "from pyspark.sql.functions import row_number, monotonically_increasing_id\n",
    "from pyspark.sql import Window\n",
    "\n",
    "#Extrating the date attribtues to create the date staging dimension table\n",
    "atm_date_staging = spark.sql(\"select distinct year,month,day,hour,weekday from atm_staging\")\n",
    "\n",
    "#Converting the Month values to euivalent numbered months values to ease addition of unix timestamp column full_date_time\n",
    "atm_date_staging= atm_date_staging.withColumn(\"tmonth\",from_unixtime(unix_timestamp(col(\"Month\"),'MMM'),'MM'))\n",
    "atm_date_staging = atm_date_staging.withColumn('full_date_time',sf.concat(sf.col('year'),sf.lit('/'),sf.col('tmonth'),sf.lit('/'),sf.col('day'),sf.lit(' '),sf.col('hour'),sf.lit(':'),sf.lit('00:00')))\n",
    "atm_date_staging = atm_date_staging.withColumn('full_date_time', unix_timestamp(atm_date_staging['full_date_time'], 'yyyy/MM/dd HH:mm:ss').cast('timestamp'))\n",
    "\n",
    "# Adding the primary key column by generating unique id \n",
    "atm_date_staging = atm_date_staging.withColumn(\n",
    "    \"date_id\",\n",
    "    row_number().over(Window.orderBy(monotonically_increasing_id()))\n",
    ")\n",
    "\n",
    "# Creating the dimension table by rearragning the columns as per expectation\n",
    "DIM_DATE=atm_date_staging.select(\"date_id\",\"full_date_time\",\"year\",\"month\",\"day\",\"hour\",\"weekday\");\n",
    "\n",
    "#Registering the df to use in join with sparlsql\n",
    "DIM_DATE.registerTempTable(\"DIM_DATE\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIM_DATE Validate the count -8685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    8685|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(1) from DIM_DATE\").show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the DIM_DATE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----+--------+---+----+---------+\n",
      "|date_id|     full_date_time|year|   month|day|hour|  weekday|\n",
      "+-------+-------------------+----+--------+---+----+---------+\n",
      "|      1|2017-01-02 16:00:00|2017| January|  2|  16|   Monday|\n",
      "|      2|2017-01-15 09:00:00|2017| January| 15|   9|   Sunday|\n",
      "|      3|2017-01-24 17:00:00|2017| January| 24|  17|  Tuesday|\n",
      "|      4|2017-02-07 11:00:00|2017|February|  7|  11|  Tuesday|\n",
      "|      5|2017-02-08 20:00:00|2017|February|  8|  20|Wednesday|\n",
      "+-------+-------------------+----+--------+---+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from DIM_DATE\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATM Card Type Dimension Table Creation - DIM_CARD_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrating the card type attribtues to create the card type staging dimension table\n",
    "atm_card_type = spark.sql(\"select distinct card_Type from atm_staging \");\n",
    "\n",
    "# Adding the primary key column by generating unique id \n",
    "atm_card_type = atm_card_type.withColumn(\n",
    "    \"card_type_id\",\n",
    "    row_number().over(Window.orderBy(monotonically_increasing_id()))\n",
    ")\n",
    "\n",
    "# Creating the dimension table by rearragning the columns as per expectation\n",
    "DIM_CARD_TYPE=atm_card_type.select(\"card_type_id\",\"card_type\");\n",
    "\n",
    "#Registering the df to use in join with sparlsql\n",
    "DIM_CARD_TYPE.registerTempTable(\"DIM_CARD_TYPE\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIM_CARD_TYPE Validate the count -12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      12|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from DIM_CARD_TYPE\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the DIM_CARD_TYPE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|card_type_id|           card_type|\n",
      "+------------+--------------------+\n",
      "|           1|     Dankort - on-us|\n",
      "|           2|              CIRRUS|\n",
      "|           3|         HÃƒÂ¦vekort|\n",
      "|           4|                VISA|\n",
      "|           5|  Mastercard - on-us|\n",
      "|           6|             Maestro|\n",
      "|           7|Visa Dankort - on-us|\n",
      "|           8|        Visa Dankort|\n",
      "|           9|            VisaPlus|\n",
      "|          10|          MasterCard|\n",
      "|          11|             Dankort|\n",
      "|          12| HÃƒÂ¦vekort - on-us|\n",
      "+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from DIM_CARD_TYPE\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fact Table Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1 : Left Outer Join of staging table and the location dimension table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "atm_ljoin_location = spark.sql(\"select dim_location.location_id,atm_staging.* \\\n",
    "                        from atm_staging \\\n",
    "                        left join dim_location\\\n",
    "                        on dim_location.location = atm_staging.atm_location \\\n",
    "                        and dim_location.streetname = atm_staging.atm_streetname \\\n",
    "                        and dim_location.street_number = atm_staging.atm_street_number \\\n",
    "                        and dim_location.lat = atm_staging.atm_lat \\\n",
    "                        and dim_location.lon = atm_staging.atm_lon\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming the atm_id column to avoid conflict while joining with the dimension table DIM_ATM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "atm_ljoin_location=atm_ljoin_location.withColumnRenamed('atm_id','atm_id_temp')\n",
    "\n",
    "atm_ljoin_location.registerTempTable(\"atm_ljoin_location\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2: Left Joining the above resultset with the DIM_ATM table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "atm_ljoin_atm = spark.sql(\"select dim_atm.atm_id,atm_ljoin_location.* \\\n",
    "                            from atm_ljoin_location \\\n",
    "                            left join dim_atm \\\n",
    "                            on dim_atm.atm_number = atm_ljoin_location.atm_id_temp \\\n",
    "                            and dim_atm.atm_manufacturer = atm_ljoin_location.atm_manufacturer \\\n",
    "                            and dim_atm.atm_location_id = atm_ljoin_location.location_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "atm_ljoin_atm.registerTempTable(\"atm_ljoin_atm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3 : Left Join above resultset with the Date Dimensional Table DIM_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "atm_ljoin_date = spark.sql(\"select dim_date.date_id,dim_date.full_date_time,atm_ljoin_atm.* \\\n",
    "                            from atm_ljoin_atm left join dim_date \\\n",
    "                            on dim_date.year = atm_ljoin_atm.year \\\n",
    "                            and dim_date.month = atm_ljoin_atm.month \\\n",
    "                            and dim_date.day = atm_ljoin_atm.day \\\n",
    "                            and dim_date.hour = atm_ljoin_atm.hour \\\n",
    "                            and dim_date.weekday = atm_ljoin_atm.weekday\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming the card_type column to avoid conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "atm_ljoin_date=atm_ljoin_date.withColumnRenamed('card_type','card_type_temp')\n",
    "atm_ljoin_date.registerTempTable(\"atm_ljoin_date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 4: Left Join the above resultset with the card type dimensional table DIM_CARD_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "atm_ljoin_card = spark.sql(\"select dim_card_type.card_type_id,atm_ljoin_date.* \\\n",
    "                            from atm_ljoin_date \\\n",
    "                            left join dim_card_type \\\n",
    "                            on dim_card_type.card_type = atm_ljoin_date.card_type_temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up the staging fact table to hold only relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "atm_ljoin_card=atm_ljoin_card.drop(\"year\",\"month\",\"day\",\"weekday\",\"hour\",\"atm_id_temp\",\"atm_manufacturer\",\"atm_location\",\n",
    "                    \"atm_streetname\",\"atm_street_number\",\"atm_zipcode\",\"atm_lat\",\"atm_lon\",\"card_type_temp\",\n",
    "                   \"weather_lat\",\"weather_lon\",\"weather_city_id\",\"weather_city_name\",\"temp\",\"pressure\",\n",
    "                   \"humidity\",\"wind_speed\",\"wind_deg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- card_type_id: integer (nullable = true)\n",
      " |-- date_id: integer (nullable = true)\n",
      " |-- full_date_time: timestamp (nullable = true)\n",
      " |-- atm_id: integer (nullable = true)\n",
      " |-- location_id: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- rain_3h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "atm_ljoin_card.printSchema();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the record in the staging fact table - 2468572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atm_ljoin_card.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the primary key for fact table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "atm_ljoin_card=atm_ljoin_card.withColumnRenamed('location_id','weather_loc_id')\n",
    "\n",
    "atm_ljoin_card = atm_ljoin_card.withColumn(\n",
    "    \"trans_id\",\n",
    "    row_number().over(Window.orderBy(monotonically_increasing_id()))\n",
    ")\n",
    "\n",
    "FACT_ATM_TRANS = atm_ljoin_card.select(\"trans_id\",\"atm_id\",\"weather_loc_id\",\"date_id\",\"card_type_id\",\"atm_status\",\n",
    "                                      \"currency\",\"service\",\"transaction_amount\",\"message_code\",\"message_text\",\n",
    "                                      \"rain_3h\",\"clouds_all\",\"weather_id\",\"weather_main\",\"weather_description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[trans_id: int, atm_id: int, weather_loc_id: int, date_id: int, card_type_id: int, atm_status: string, currency: string, service: string, transaction_amount: int, message_code: string, message_text: string, rain_3h: double, clouds_all: int, weather_id: int, weather_main: string, weather_description: string]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FACT_ATM_TRANS.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fact Table Validation wrt to count and unique values for the respective foriegn keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FACT_ATM_TRANS.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FACT_ATM_TRANS.filter(FACT_ATM_TRANS.trans_id.isNotNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FACT_ATM_TRANS.filter(FACT_ATM_TRANS.atm_id.isNotNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FACT_ATM_TRANS.filter(FACT_ATM_TRANS.weather_loc_id.isNotNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FACT_ATM_TRANS.filter(FACT_ATM_TRANS.date_id.isNotNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FACT_ATM_TRANS.filter(FACT_ATM_TRANS.card_type_id.isNotNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the data for the FACT_ATM_TRANS DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------+-------+------------+----------+\n",
      "|trans_id|atm_id|weather_loc_id|date_id|card_type_id|atm_status|\n",
      "+--------+------+--------------+-------+------------+----------+\n",
      "|       1|    14|            82|     10|           1|    Active|\n",
      "|       2|    21|            85|     10|           1|    Active|\n",
      "|       3|    26|             4|     10|           1|    Active|\n",
      "|       4|    30|            16|     10|           1|    Active|\n",
      "|       5|    30|            16|     10|           1|    Active|\n",
      "+--------+------+--------------+-------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FACT_ATM_TRANS.select(\"trans_id\",\"atm_id\",\"weather_loc_id\",\"date_id\",\"card_type_id\",\"atm_status\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer the dimension and fact table to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption : Necessay configuration are done to integrate S3 and cdh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_LOCATION.write.save(\"s3a://upgradjjassignment/ETL/DIM_LOCATION\",format='csv',header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_ATM.write.save(\"s3a://upgradjjassignment/ETL/DIM_ATM\",format='csv',header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_DATE.write.save(\"s3a://upgradjjassignment/ETL/DIM_DATE\",format='csv',header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_CARD_TYPE.write.save(\"s3a://upgradjjassignment/ETL/DIM_CARD_TYPE\",format='csv',header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACT_ATM_TRANS.write.save(\"s3a://upgradjjassignment/ETL/FACT_ATM_TRANS\",format='csv',header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
